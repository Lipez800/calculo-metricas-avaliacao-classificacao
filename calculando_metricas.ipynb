{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc15b13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tabulate não encontrado. Usando formato simples.\n",
      "Matriz de Confusão:\n",
      "VP: 100, VN: 90, FP: 10, FN: 5\n",
      "\n",
      "Formato Visual:\n",
      "                 Predito\n",
      "              Pos   Neg\n",
      "Real  Pos    100     5\n",
      "      Neg     10    90\n",
      "\n",
      "Métricas de Avaliação:\n",
      "------------------------------\n",
      "Métrica         Valor     \n",
      "------------------------------\n",
      "Acurácia        0.9268\n",
      "Sensibilidade   0.9524\n",
      "Especificidade  0.9000\n",
      "Precisão        0.9091\n",
      "F-score         0.9302\n",
      "------------------------------\n",
      "\n",
      "==================================================\n",
      "TESTE COM OUTRA MATRIZ DE CONFUSÃO:\n",
      "==================================================\n",
      "Matriz de Confusão:\n",
      "VP: 80, VN: 70, FP: 30, FN: 20\n",
      "\n",
      "Formato Visual:\n",
      "                 Predito\n",
      "              Pos   Neg\n",
      "Real  Pos     80    20\n",
      "      Neg     30    70\n",
      "\n",
      "Métricas de Avaliação:\n",
      "------------------------------\n",
      "Métrica         Valor     \n",
      "------------------------------\n",
      "Acurácia        0.7500\n",
      "Sensibilidade   0.8000\n",
      "Especificidade  0.7000\n",
      "Precisão        0.7273\n",
      "F-score         0.7619\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Versão sem pandas - usando tabulate ou formato simples\n",
    "try:\n",
    "    from tabulate import tabulate\n",
    "    TABULATE_AVAILABLE = True\n",
    "except ImportError:\n",
    "    TABULATE_AVAILABLE = False\n",
    "    print(\"tabulate não encontrado. Usando formato simples.\")\n",
    "\n",
    "def calculate_metrics(confusion_matrix):\n",
    "    \"\"\"\n",
    "    Calcula as métricas de avaliação de um modelo de classificação.\n",
    "    \n",
    "    Args:\n",
    "        confusion_matrix (dict): Dicionário contendo os valores da matriz de confusão.\n",
    "            Exemplo: {'VP': 100, 'VN': 90, 'FP': 10, 'FN': 5}\n",
    "    \n",
    "    Returns:\n",
    "        dict: Um dicionário com as métricas calculadas.\n",
    "    \"\"\"\n",
    "    # Extrair valores da matriz de confusão\n",
    "    VP = confusion_matrix['VP']\n",
    "    VN = confusion_matrix['VN']\n",
    "    FP = confusion_matrix['FP']\n",
    "    FN = confusion_matrix['FN']\n",
    "    \n",
    "    # Calcular total de amostras (N) - CORRIGIDO!\n",
    "    N = VP + VN + FP + FN  # Todos os elementos da matriz de confusão\n",
    "    \n",
    "    # Calcular métricas\n",
    "    accuracy = (VP + VN) / N if N > 0 else 0\n",
    "    sensitivity = VP / (VP + FN) if (VP + FN) > 0 else 0\n",
    "    specificity = VN / (FP + VN) if (FP + VN) > 0 else 0\n",
    "    precision = VP / (VP + FP) if (VP + FP) > 0 else 0\n",
    "    \n",
    "    # Calcular F-score\n",
    "    if precision == 0 or sensitivity == 0:\n",
    "        f_score = 0\n",
    "    else:\n",
    "        f_score = 2 * (precision * sensitivity) / (precision + sensitivity)\n",
    "    \n",
    "    # Retornar métricas como um dicionário\n",
    "    metrics = {\n",
    "        'Acurácia': accuracy,\n",
    "        'Sensibilidade': sensitivity,\n",
    "        'Especificidade': specificity,\n",
    "        'Precisão': precision,\n",
    "        'F-score': f_score\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def print_formatted_table(metrics):\n",
    "    \"\"\"\n",
    "    Imprime as métricas em formato de tabela formatada\n",
    "    \"\"\"\n",
    "    if TABULATE_AVAILABLE:\n",
    "        # Usar tabulate para tabela formatada\n",
    "        headers = [\"Métrica\", \"Valor\"]\n",
    "        rows = [[metric, f\"{value:.4f}\"] for metric, value in metrics.items()]\n",
    "        print(\"\\nMétricas de Avaliação:\")\n",
    "        print(tabulate(rows, headers=headers, tablefmt=\"grid\"))\n",
    "    else:\n",
    "        # Formato simples caso tabulate não esteja disponível\n",
    "        print(\"\\nMétricas de Avaliação:\")\n",
    "        print(\"-\" * 30)\n",
    "        print(f\"{'Métrica':<15} {'Valor':<10}\")\n",
    "        print(\"-\" * 30)\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"{metric:<15} {value:.4f}\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "def print_confusion_matrix(confusion_matrix):\n",
    "    \"\"\"\n",
    "    Imprime a matriz de confusão de forma visual\n",
    "    \"\"\"\n",
    "    VP = confusion_matrix['VP']\n",
    "    VN = confusion_matrix['VN']\n",
    "    FP = confusion_matrix['FP']\n",
    "    FN = confusion_matrix['FN']\n",
    "    \n",
    "    print(\"Matriz de Confusão:\")\n",
    "    print(f\"VP: {VP}, VN: {VN}, FP: {FP}, FN: {FN}\")\n",
    "    \n",
    "    # Formato visual da matriz\n",
    "    print(\"\\nFormato Visual:\")\n",
    "    print(\"                 Predito\")\n",
    "    print(\"              Pos   Neg\")\n",
    "    print(f\"Real  Pos    {VP:>3}   {FN:>3}\")\n",
    "    print(f\"      Neg    {FP:>3}   {VN:>3}\")\n",
    "\n",
    "# Exemplo de uso\n",
    "if __name__ == \"__main__\":\n",
    "    # Definir uma matriz de confusão arbitrária\n",
    "    confusion_matrix = {\n",
    "        'VP': 100,  # Verdadeiros Positivos\n",
    "        'VN': 90,   # Verdadeiros Negativos\n",
    "        'FP': 10,   # Falsos Positivos\n",
    "        'FN': 5     # Falsos Negativos\n",
    "    }\n",
    "    \n",
    "    # Imprimir Matriz de Confusão\n",
    "    print_confusion_matrix(confusion_matrix)\n",
    "    \n",
    "    # Calcular métricas\n",
    "    metrics = calculate_metrics(confusion_matrix)\n",
    "    \n",
    "    # Imprimir Métricas Formatadas\n",
    "    print_formatted_table(metrics)\n",
    "    \n",
    "    # Testar com diferentes matrizes de confusão\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"TESTE COM OUTRA MATRIZ DE CONFUSÃO:\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Exemplo de modelo com mais erros\n",
    "    confusion_matrix_2 = {\n",
    "        'VP': 80,   # Menos verdadeiros positivos\n",
    "        'VN': 70,   # Menos verdadeiros negativos\n",
    "        'FP': 30,   # Mais falsos positivos\n",
    "        'FN': 20    # Mais falsos negativos\n",
    "    }\n",
    "    \n",
    "    print_confusion_matrix(confusion_matrix_2)\n",
    "    metrics_2 = calculate_metrics(confusion_matrix_2)\n",
    "    print_formatted_table(metrics_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
