# C√°lculo de M√©tricas de Avalia√ß√£o de Classifica√ß√£o

## üéØ Descri√ß√£o do Projeto
Este projeto implementa o c√°lculo das principais m√©tricas de avalia√ß√£o para modelos de classifica√ß√£o de machine learning: Acur√°cia, Sensibilidade (Recall), Especificidade, Precis√£o e F-score. Parte do desafio de Avalia√ß√£o de Modelos da Digital Innovation One (DIO).

## üöÄ Tecnologias Utilizadas
- Python 3.x
- NumPy para c√°lculos matem√°ticos
- Tabulate para formata√ß√£o de tabelas (opcional)

## üìä Funcionalidades Implementadas
- **C√°lculo de M√©tricas**: Acur√°cia, Sensibilidade, Especificidade, Precis√£o e F-score
- **Matriz de Confus√£o**: Visualiza√ß√£o dos valores VP, VN, FP, FN
- **Formata√ß√£o Profissional**: Tabelas formatadas para f√°cil leitura
- **Tratamento de Erros**: Preven√ß√£o de divis√£o por zero
- **Testes com Diferentes Cen√°rios**: Compara√ß√£o de desempenho de modelos


## üéì Projeto Desenvolvido para Digital Innovation One (DIO)
Parte do desafio de C√°lculo de M√©tricas de Avalia√ß√£o de Aprendizado

## üìö M√©tricas Calculadas

| M√©trica | F√≥rmula | Descri√ß√£o |
|---------|---------|-----------|
| **Acur√°cia** | (VP + VN) / N | Propor√ß√£o de predi√ß√µes corretas |
| **Sensibilidade** | VP / (VP + FN) | Capacidade de detectar positivos |
| **Especificidade** | VN / (FP + VN) | Capacidade de detectar negativos |
| **Precis√£o** | VP / (VP + FP) | Confiabilidade das predi√ß√µes positivas |
| **F-score** | 2 √ó (P √ó S) / (P + S) | M√©dia harm√¥nica de Precis√£o e Sensibilidade |

## üåü **Sobre o Projeto:**

Este √© um projeto educacional focado em ensinar como calcular e interpretar m√©tricas de avalia√ß√£o de modelos de classifica√ß√£o. Perfeito para iniciantes em machine learning que querem entender como avaliar a performance dos seus modelos.

O c√≥digo √© auto-contido em um √∫nico arquivo, tornando-o f√°cil de executar e entender!

## üéØ Exemplo de Uso
```python
confusion_matrix = {
    'VP': 100,  # Verdadeiros Positivos
    'VN': 90,   # Verdadeiros Negativos  
    'FP': 10,   # Falsos Positivos
    'FN': 5     # Falsos Negativos
}

metrics = calculate_metrics(confusion_matrix) 
# Resultados: Acur√°cia=92.68%, Sensibilidade=95.24%, etc.
